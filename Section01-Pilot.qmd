---
format:
  typst: default
execute:
  cache: true
output-dir: artifacts/pilot/
---

```{r, setup}
library(dplyr)
library(tidyr)
library(purrr)

library(ggplot2)
library(patchwork)

# Set the color palette for plotting.
arcpal <- list('#2B2B2B', '#248ADA', '#C71010', '#1FC719', '#F7DE28', 
               '#878494', '#F954F2', '#EE6000', '#6B23A9', '#8B5A28')

names(arcpal) <- as.character(0:9)

# Read in the datasets.
load('data/ET-Pilot.rda')
training <- mutate(training, task=factor(task, 1:40)) |> drop_na(task)

set.seed(200)
```

```{r, eda-attempts}
attempts <-
  behavioral  |>
  
  # Those participants with eyetracking data.
  inner_join(subject_id_map) |>
  
  # Remove the calibration grids.
  filter(problem <= 40) |>
  
  # Extract the number of attempts per problem.
  summarize(.by=c(subject, problem), n_attempts=max(attempt), last = last[which.max(n_attempts)]) |>
  
  # Yes or no, was the participant successful on their first try.
  mutate(first_try = last == 'submit' & n_attempts == 1)

attempts_by_problem <-
  attempts |>
  summarize(.by=problem, prob_first_try=mean(first_try), median_attempts=median(n_attempts)) |>
  arrange(problem)
```

Participants found the correct answer on their first attempt with an average probability of `r with(attempts_by_problem, sprintf('%.2f (SD=%.2f)', mean(prob_first_try), sd(prob_first_try)))` over the 40 problems.

For the following we will use Task 1 (@fig-task-1) as a case study. @fig-pilot-fixation-prob shows us the raw probabilities and counts of fixation on a particular coordinate of Task 1.

```{r, eda-fixation-counts}
#| label: fig-pilot-fixation-prob
#| fig-width: 6
#| fig-height: 6
#| fig-cap: "Raw fixation counts for Task 1."

grid_sizes <-
  distinct(training, task, x, y) |>
  summarise(.by=task, across(x:y, n_distinct), max=max(x,y))

dimens <-  grid_sizes[grid_sizes[['task']] == 1, 'max']

 d <- filter(etdata, problem == 1) |>
  filter(ROI %in% 1:8) |>
  drop_na(tileX, tileY) |>
  mutate(
    # Are we looking at an example or test grid?
    phase = 
      paste0(
        if_else(between(ROI, 1, 6), 'E', 'Query'),
        case_when(
          ROI %in% 1:2 ~ '1',
          ROI %in% 3:4 ~ '2',
          ROI %in% 5:6 ~ '3',
          ROI %in% 7:8 ~ ''
        )
      ),
    
    # Are we looking at an input grid or an output grid?
    io = 
      case_when(ROI %in% c(1,3,5,7) ~ 0, .default=1) |>
      factor(0:1, c('In', 'Out')),
    
    across(tileX:tileY, \(x) factor(x, seq_len(dimens)))
  ) |>
  count(phase, io, tileX, tileY, .drop=FALSE) |>
  mutate(.by=c(phase, io), grid_total=sum(n), grid_prob=n/grid_total) |>
  mutate(across(tileX:tileY, as.integer), overall_prob=n/sum(n))

 
 
p <- ggplot(d, aes(tileY, -tileX)) +
  facet_grid(io ~ phase, switch='y')

# plot customizations common to both plots
(
  (p + geom_raster(aes(fill=grid_prob)) +
    scale_fill_continuous('Fixation Probability\n(Within Grid)', type='viridis')
   ) /
  (p + geom_raster(aes(fill=overall_prob)) +
    scale_fill_continuous('Fixation Probability\n(Overall)', type='viridis')
   )
) * list(
  geom_text(aes(label=n), size = 6 / .pt),
  geom_text(aes(label=paste(grid_total, 'Total Fixations')), x=dimens+.5, y=-dimens-1, hjust=1, check_overlap=TRUE, size = 6 / .pt),
  
  labs(x = NULL, y = NULL),
  scale_x_discrete(),
  scale_y_discrete(),
  coord_fixed(clip='off'),
  theme_minimal(),
  theme(plot.margin = unit(rep(0, 4), "null"), panel.spacing = unit(0, "null"))
)
```

This schema will be applied in an information theoretic analysis of the fixations on a per problem basis.

## Method and Model Selection

We will calculate the Shannon Entropy for each subject, for each problem, for each example, on the probability distribution shown in @fig-pilot-fixation-prob. We will use only the participants fixations on the Example grids (E1-E3) as fixations on the query grid are contaminated by the participants' editing of their solution.

```{r}
da <- map_dfr(1:40, \(i) {


dimens <-  grid_sizes[grid_sizes[['task']] == i, 'max']

 filter(etdata, problem == i) |>
  filter(ROI %in% 1:8) |>
  drop_na(tileX, tileY) |>
  mutate(
    # Are we looking at an example or test grid?
    phase = 
      paste0(
        if_else(between(ROI, 1, 6), 'E', 'Query'),
        case_when(
          ROI %in% 1:2 ~ '1',
          ROI %in% 3:4 ~ '2',
          ROI %in% 5:6 ~ '3',
          ROI %in% 7:8 ~ ''
        )
      ),
    
    # Are we looking at an input grid or an output grid?
    io = 
      case_when(ROI %in% c(1,3,5,7) ~ 0, .default=1) |>
      factor(0:1, c('In', 'Out')),
    
    across(tileX:tileY, \(x) factor(x, seq_len(dimens)))
  ) |>
  count(subject, phase, io, tileX, tileY, .drop=FALSE) |>
  mutate(.by=c(phase, io), grid_total=sum(n), grid_prob=n/grid_total) |>
  mutate(across(tileX:tileY, as.integer), overall_prob=n/sum(n)) |>
  mutate(.before=1, problem=i, )
})

da |>
  left_join(mutate(.keep='none', grid_sizes, problem=as.integer(task), w=x,h=y)) |>
  filter(stringr::str_detect(phase, '^E')) |>
  mutate(
    .by=c(subject, problem, phase),
    area=w[1]*h[1],
    p = n/area + .00000001, # add tiny constant to avoid NaNs
    sls = p*log2(p)
  ) |>
  summarize(
        .by=c(subject, problem, phase),
        H=-sum(p*log2(p))
  ) |>
  pivot_wider(names_from=phase, values_from=H) |>
  left_join(attempts) |>
  mutate(.keep='none', Subject=subject, `Task Item`=problem, `E1 Entropy`=E1, `E2 Entropy`=E2, `E3 Entropy`=E3, `Correct On First Try`=as.integer(first_try)) -> data
```

```{r, echo=TRUE}
head(data)
```

Given success on first try as a binary outcome, with the three gaze entropies as continuous predictors, we will model our data using a multivariate logistic regression. We will also include in our model whether or not the participant looked at each of the Example grids. We choose to include this predictor because it is possible that a participant might look, for example, only at the first grid, and rush to a solution before taking in all of the information.

```{r}
names(data) <- c('subject', 'item', 'e1', 'e2', 'e3', 'correct')

model <- lm(correct ~ e1 + e2 + e3, data)

summary(model)

library(lme4)

model <- glmer(correct ~ e1 + e2 + e3 + (1|item), data, binomial)

summary(model)
```
